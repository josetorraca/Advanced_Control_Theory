{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capron_FinalWork_v4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Building the custom environment for OpenAi Gym\n",
        "\n",
        "from gym import Env \n",
        "# Env is a placeholder class that allows us to build our environment\n",
        "\n",
        "from gym.spaces import Box\n",
        "# Superclass that is used to define observation and action spaces\n",
        "#`Box` is for continuing-space, `Discrete` for discrete-space and `Dict` for multiple input\n",
        "# https://github.com/openai/gym/blob/master/gym/spaces/box.py\n",
        "\"\"\"Implementation of a space that represents closed boxes in euclidean space.\"\"\"\n",
        "\"\"\"\n",
        "class Box(Space[np.ndarray]):\n",
        "    A (possibly unbounded) box in :math:`\\mathbb{R}^n`.\n",
        "    Specifically, a Box represents the Cartesian product of n closed intervals.\n",
        "    Each interval has the form of one of :math:`[a, b]`, :math:`(-\\infty, b]`,\n",
        "    :math:`[a, \\infty)`, or :math:`(-\\infty, \\infty)`.\n",
        "    There are two common use cases:\n",
        "    * Identical bound for each dimension::\n",
        "        >>> Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)\n",
        "        Box(3, 4)\n",
        "    * Independent bound for each dimension::\n",
        "        >>> Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)\n",
        "        Box(2,)\n",
        "    \n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# (This removes np.float32 warnings, but can be solved with np.float64 at \"box\" definition):\n",
        "# gym.logger.set_level(40) \n",
        "\n",
        "class Model(Env):\n",
        "# By passing Env to the class Model we defined, we inherit the methods and properties of OpenAI Gym\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # Actions we can take, we only have the valve opening at each timestep (we consider a lower/upper bound of |1.0e-3|)\n",
        "        self.action_space = Box(low=np.array([-1.0e-6]), high=np.array([1.0e-6]), dtype=np.float64)\n",
        "        # The function \"Box\" can support a tensor\n",
        "\n",
        "        # # Valve opening observation array (maximum physically possible opening of 1.0)\n",
        "        # self.valve_opening  = Box(low=np.array([0.00]), high=np.array([1.00]), dtype=np.float64)\n",
        "\n",
        "        # # Water Height observation array (assuming Maximum Height of Tank of 1.0 m)\n",
        "        # self.water_height = Box(low=np.array([0.00]), high=np.array([1.00]), dtype=np.float64)\n",
        "\n",
        "        # Inflow observation array (assuming Maximum Possible Flow of 150 m³/h) / remember: Inflow is not a state!\n",
        "        # self.inflow = Box(low=np.array([0.00]), high=np.array([150.00]), dtype=np.float64)\n",
        "\n",
        "        # Observation space array (only Valve opening and Water Height; both with lower bound 0.0 and upper bound 1.0)\n",
        "        self.observation_space = Box(low=0.0, high=1.0, shape=(1, 2), dtype=np.float64)\n",
        "\n",
        "        # Set observation space (reminder: flow isn't measured/ isn't a state)\n",
        "        # self.observation_space = (self.inflow , self.valve_opening, self.water_height)\n",
        "\n",
        "        ## Area of 3 m²\n",
        "        ## Diameter of 1.95441 m\n",
        "        self.tank_diameter = 1.95441\n",
        "\n",
        "        # Set initial states (we can instantiate them a bit randomly - 10% var):\n",
        "        # self.current_inflow = 100 + random.uniform(-10.00, 10.00)\n",
        "        # self.current_valve_opening = 0.5 + random.uniform(-0.05, 0.05)\n",
        "        # self.current_water_height = 0.5 + random.uniform(-0.05, 0.05)\n",
        "\n",
        "        self.current_inflow = 100\n",
        "        self.current_valve_opening = 0.5\n",
        "        self.current_water_height = 0.5\n",
        "\n",
        "        ##  Calculate Volume of Water inside Tank\n",
        "        ##  Maximum Possible Volume of 3.0 m³\n",
        "        self.current_water_volume = (((self.tank_diameter / 2) ** 2) * np.pi) * self.current_water_height\n",
        "\n",
        "        ## Valve coefficient (Cv) is given\n",
        "        self.valve_coefficient = 282.84\n",
        "\n",
        "        ## Setpoint in terms of the Usual Operation Height of 0.5 m \n",
        "        self.setpoint =  0.5\n",
        "\n",
        "        # Tolerance acceptable for setpoint error (in reward definition):\n",
        "        self.tolerance = 1e-4 # test 1e-6\n",
        "       \n",
        "        self.state = (self.current_valve_opening, self.current_water_height)\n",
        "\n",
        "        # Set episode length\n",
        "        ## Timestep = 0.01h\n",
        "        ## Episode total time = 2h (200 timesteps)\n",
        "        ## Total number of episodes = 2000\n",
        "        self.time_per_episode = 200\n",
        "\n",
        "        # Initialize time counter\n",
        "        self.time_step = 0\n",
        "\n",
        "    ## Provides current water height from the most up to date water volume\n",
        "    def update_water_height(self):\n",
        "        return self.current_water_volume / (((self.tank_diameter / 2) ** 2) * np.pi)   \n",
        "   \n",
        "    ## Calculates the non-linear outflow rate of water from the tank\n",
        "    def outflow(self):\n",
        "        return self.valve_coefficient * self.current_valve_opening * np.sqrt(abs(self.update_water_height())) \n",
        "\n",
        "    ## Error of water height from current set point\n",
        "    def error(self):\n",
        "        error=(self.update_water_height() - self.setpoint)\n",
        "        return error\n",
        "        \n",
        "    def step(self, action):\n",
        "\n",
        "        # Flow rate of water + disturbances\n",
        "        self.current_inflow = self.current_inflow + self.disturbance(self.time_step)\n",
        "\n",
        "        ## Current water volume in the tank\n",
        "        self.current_water_volume = self.current_water_volume + self.current_inflow - self.outflow()\n",
        "\n",
        "        ## Update current water height\n",
        "        self.current_water_height = self.update_water_height()\n",
        "\n",
        "        # Apply action (valve opening)\n",
        "        # Continuous: [-0.01, 0.01] at each timestep\n",
        "        self.current_valve_opening =  self.current_valve_opening + action\n",
        "\n",
        "        # Add 1 Timestep = 0.01h\n",
        "        self.time_step += 1\n",
        "        \n",
        "        # Calculate reward\n",
        "        ## Reward: minus the square of height error -(m)^2\n",
        "        ## Our objective is to minimize this error (or negative reward)\n",
        "        # reward = -((self.error())**2)\n",
        "\n",
        "        if (self.error())**2 <= self.tolerance : \n",
        "            reward = 1 \n",
        "        else: \n",
        "            reward = -1 \n",
        "\n",
        "        ## Determine whether it is a terminal state\n",
        "        terminal = self.is_terminal(self.current_water_height)\n",
        "\n",
        "        # Set placeholder for info\n",
        "        info = {}\n",
        "\n",
        "        # Return step information\n",
        "        return self.retrieve_observation(), reward, terminal, info\n",
        "\n",
        "    ## The terminal state is reached if time step reaches more than 200 or if water level is at 2 extremes\n",
        "    def is_terminal(self, water_h):\n",
        "        if self.time_step >= self.time_per_episode-1 or self.current_water_height <= 0 or self.current_water_height >= 1:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    ## Disturbances on flow rate:\n",
        "    def disturbance(self, time):\n",
        "        if self.time_step == 10: #0.1 h\n",
        "            return 20\n",
        "        elif self.time_step == 100: #1.1 h\n",
        "            return -20\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    ## Retrieve current state\n",
        "    def retrieve_observation(self):\n",
        "\n",
        "        self.state = (\n",
        "            self.current_valve_opening, self.current_water_height\n",
        "        )\n",
        "        return self.state\n",
        "\n",
        "    def render(self):\n",
        "        # Implement visualization for a game environment for example\n",
        "        pass\n",
        "    \n",
        "    ## Reset the current state of the water tank. This involves time_step, water volume, input flow rate of water and error\n",
        "    def reset(self):\n",
        "\n",
        "        ## Set point remains fixed:\n",
        "        self.setpoint = 0.5\n",
        "\n",
        "        ## Reset time counter and other variables (we can instantiate them as before, a bit randomly)\n",
        "        self.time_step = 0\n",
        "        # self.current_inflow = 100 + random.uniform(-10.00, 10.00)\n",
        "        # self.current_valve_opening = 0.5 + random.uniform(-0.05, 0.05)\n",
        "        # self.current_water_height = 0.5 + random.uniform(-0.05, 0.05)\n",
        "\n",
        "        self.current_inflow = 100\n",
        "        self.current_valve_opening = 0.5\n",
        "        self.current_water_height = 0.5\n",
        "\n",
        "        return self.retrieve_observation()"
      ],
      "metadata": {
        "id": "vmPSaefw5pyx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = Model()"
      ],
      "metadata": {
        "id": "iGymX9b9hQAw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to see if the bounds of observation space (H and Xv) are defined correctly\n",
        "\n",
        "a = env.observation_space.low\n",
        "print(a)\n",
        "\n",
        "b = env.observation_space.high\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrhfH7EqNKN",
        "outputId": "7c597095-0d29-4efb-ca0e-17888980b06d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0.]]\n",
            "[[1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getattr() – This function is used to access the attribute of object, like a class.\n",
        "\n",
        "print (getattr(env,'time_step')) \n",
        "print (getattr(env,'current_inflow')) \n",
        "print (getattr(env,'current_valve_opening')) \n",
        "print (getattr(env,'current_water_height')) \n",
        "print (getattr(env,'setpoint')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Wq_MxXcWSX",
        "outputId": "d63c0f44-6ef1-4882-b61b-624b5e7dbe87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "0.5\n",
            "0.5\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Python calling method (error) in class (model/'env')\n",
        "\n",
        "env.error()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8rVSzOdejQX",
        "outputId": "971cc3a4-4d82-4e08-eb87-d2b7cfb05c8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.update_water_height()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5UMjsEki75_",
        "outputId": "cb2a4e24-989c-41bc-d982-5853d862527c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.outflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztIyuSfSphfe",
        "outputId": "936eac5e-1c34-4efd-f45a-82f3956fbcbc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.99904099540154"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python calling method (step) in class (model/'env')\n",
        "# Just to see 1 step, with an action of +0.01 on Xv (valve_opening)\n",
        "\n",
        "env.step(0.0001)\n",
        "\n",
        "# Remember of the output we defined from retrieve.observation():\n",
        "# self.current_water_volume, self.current_inflow , self.current_valve_opening, self.current_water_height, self.setpoint, self.error()\n",
        "\n",
        "# And after we have also from the return of step(): \n",
        "# reward, terminal, info."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avycnFncf-jg",
        "outputId": "64e70b6e-9fa5-4b2f-9202-b7f6f89280cd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.5001, 0.5003196682150601), 1, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.outflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8d7avGapbp0",
        "outputId": "e527370d-fe04-4083-87a3-3aba559e9c42"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.05100860311804"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python calling method (step) in class (model/'env')\n",
        "# Just to see 1 step, with an action of +0.01 on Xv (valve_opening)\n",
        "\n",
        "env.step(0.0001)\n",
        "\n",
        "# Remember of the output we defined from retrieve.observation():\n",
        "# self.current_water_volume, self.current_inflow , self.current_valve_opening, self.current_water_height, self.setpoint, self.error()\n",
        "\n",
        "# And after we have also from the return of step(): \n",
        "# reward, terminal, info."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmvxfgjn7tG",
        "outputId": "5317d281-b9bb-4e30-c6d0-3d78c4b4a878"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.5002, 0.4833167996806295), -1, False, {})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.outflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o07QqUj6oOkk",
        "outputId": "f8d1efea-3bd4-43b2-e17f-721f998dd2e5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.35591014446949"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python calling method (step) in class (model/'env')\n",
        "# Just to see 1 step, with an action of +0.01 on Xv (valve_opening)\n",
        "\n",
        "env.step(0.0001)\n",
        "\n",
        "# Remember of the output we defined from retrieve.observation():\n",
        "# self.current_water_volume, self.current_inflow , self.current_valve_opening, self.current_water_height, self.setpoint, self.error()\n",
        "\n",
        "# And after we have also from the return of step(): \n",
        "# reward, terminal, info."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khq6s4zo1Tcl",
        "outputId": "05b7aead-bafe-4a40-c6bf-6b4d12a24352"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.5003, 1.0313467782254153), -1, True, {})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.outflow()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6_xOeRY1Zdn",
        "outputId": "e5313dd2-f775-4a30-8670-339a7e79e905"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143.70559910235374"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This allows us to see numpy arrays with more precision\n",
        "# (print with a higher number of digits of precision for floating point output)\n",
        "\n",
        "np.set_printoptions(precision=4) "
      ],
      "metadata": {
        "id": "_odFivI0m7YR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to confirm that the observation space (of valve_opening) is a continuum between [0, 1]\n",
        "\n",
        "env.observation_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHjjn5VyinJk",
        "outputId": "8be95a17-42b3-468c-db04-ded01b8fe546"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5055, 0.5021]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to confirm that the action space (of valve_opening) is a continuum between [-0.01, 0.01]\n",
        "\n",
        "env.action_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LQO41lkiz23",
        "outputId": "33c392c5-6807-46e5-f3f3-e27d14f5c1f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.3264e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to test the environment with random control actions\n",
        "# The score is similar to return (sum of rewards)\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        #env.render()\n",
        "        action = env.action_space.sample() #take a random action from the action space\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))"
      ],
      "metadata": {
        "id": "ICMqQ7nwm-DC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f821636-4b18-48ca-8072-bc9175484b9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-1\n",
            "Episode:2 Score:-1\n",
            "Episode:3 Score:-1\n",
            "Episode:4 Score:-1\n",
            "Episode:5 Score:-1\n",
            "Episode:6 Score:-1\n",
            "Episode:7 Score:-1\n",
            "Episode:8 Score:-1\n",
            "Episode:9 Score:-1\n",
            "Episode:10 Score:-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "derIMVclzEKF",
        "outputId": "ebcd7165-62ea-4cf2-e254-9ccd4012f396"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.493]), array([-3.5217e+10]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SARSA-lambda with Gaussian radial basis functions for action-value approximation\n",
        "# Implemented for the OpenAI gym mountain-car environment\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initializations\n",
        "env = Model()\n",
        "states = env.observation_space.shape\n",
        "# actions = env.action_space.n  # this is for discrete action space\n",
        "num_actions = env.action_space.shape\n",
        "num_actions_int  = sum(num_actions)  # transforming tuple on integer\n",
        "dim = env.observation_space.high.size\n",
        "\n",
        "num_actions = 3\n",
        "\n",
        "# Parameters\n",
        "# eps = 0.1, Lambda = 0.5, alpha = 0.008, gamma = 0.99\n",
        "num_rbf = 4 * np.ones(num_actions).astype(int)\n",
        "width = 1. / (num_rbf - 1.)\n",
        "rbf_sigma = width[0] / 2.\n",
        "epsilon = 0.1\n",
        "epsilon_final = 0.1\n",
        "Lambda = 0.5\n",
        "alpha = 0.01\n",
        "gamma = 0.99\n",
        "num_episodes = 2000\n",
        "num_timesteps = 200\n",
        "\n",
        "xbar = np.zeros((2, dim))\n",
        "xbar[0, :] = env.observation_space.low\n",
        "xbar[1, :] = env.observation_space.high\n",
        "num_ind = np.prod(num_rbf)\n",
        "activations = np.zeros(num_ind)\n",
        "new_activations = np.zeros(num_ind)\n",
        "theta = np.zeros((num_ind, num_actions))\n",
        "rbf_den = 2 * rbf_sigma ** 2\n",
        "epsilon_coefficient = (epsilon - epsilon_final) ** (1. / num_episodes)\n",
        "ep_length = np.zeros(num_episodes)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Construct ndarray of rbf centers\n",
        "c = np.zeros((num_ind, dim))\n",
        "for i in range(num_rbf[0]):\n",
        "    for j in range(num_rbf[1]):\n",
        "        c[i*num_rbf[1] + j, :] = (i * width[1], j * width[0])\n",
        "\n",
        "\n",
        "# Returns the state scaled between 0 and 1\n",
        "def normalize_state(_s):\n",
        "    _y = np.zeros(len(_s))\n",
        "    for _i in range(len(_s)):\n",
        "        _y[_i] = (_s[_i] - xbar[0, _i]) / (xbar[1, _i] - xbar[0, _i])\n",
        "    return _y\n",
        "\n",
        "# Returns an ndarray of radial basis function activations\n",
        "def phi(_state):\n",
        "    _phi = np.zeros(num_ind)\n",
        "    for _k in range(num_ind):\n",
        "        _phi[_k] = np.exp(-np.linalg.norm(_state - c[_k, :]) ** 2 / rbf_den)\n",
        "    return _phi\n",
        "\n",
        "# Returns an action following an epsilon-greedy policy\n",
        "def epsilon_greedy(_epsilon, _vals):\n",
        "    _rand = np.random.random()\n",
        "    if _rand < 1. - _epsilon:\n",
        "        _action = _vals.argmax()\n",
        "    else:\n",
        "        _action = env.action_space.sample()\n",
        "    return int(_action)\n",
        "\n",
        "# Returns the value of each action at some state\n",
        "def action_values(_activations, _theta):\n",
        "    _val = np.dot(_theta.T, _activations)\n",
        "    return _val\n",
        "\n",
        "# Returns the value of an action at some state\n",
        "def action_value(_activations, _action, _theta):\n",
        "    _val = np.dot(_theta[:, _action], _activations)\n",
        "    return _val"
      ],
      "metadata": {
        "id": "bcKs8CB66B09"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SARSA loop\n",
        "for ep in range(num_episodes):\n",
        "\n",
        "    e = np.zeros((num_ind, num_actions))\n",
        "    state = env.reset()\n",
        "    activations = phi(state)\n",
        "    # print \"activations = \", np.reshape(activations.ravel(order='F'), (num_rows, num_cols))\n",
        "    vals = action_values(activations, theta)\n",
        "    action = epsilon_greedy(epsilon, vals)\n",
        "\n",
        "    # Each episode\n",
        "    for t in range(num_timesteps):\n",
        "\n",
        "        # env.render()\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        # new_state = normalize_state(new_state)\n",
        "        new_activations = phi(new_state)\n",
        "        new_vals = action_values(new_activations, theta)\n",
        "        new_action = epsilon_greedy(epsilon, new_vals)\n",
        "        Q = action_value(activations, action, theta)\n",
        "        Q_new = action_value(new_activations, new_action, theta)\n",
        "        if done:\n",
        "            target = reward - Q\n",
        "        else:\n",
        "            target = reward + gamma * Q_new - Q\n",
        "        # e[:, action] += activations  # accumulating traces\n",
        "        e[:, action] = activations  # replacing traces\n",
        "\n",
        "        for k in range(num_ind):\n",
        "            for a in range(num_actions):\n",
        "                theta[k, a] += alpha * target * e[k, a]\n",
        "        e *= gamma * Lambda\n",
        "\n",
        "        if t % 1 != 0:\n",
        "            # print \"t = \", t\n",
        "            # print \"new_state = \", new_state\n",
        "            # print \"new_activations = \", np.reshape(new_activations.ravel(order='F'), (num_rows, num_cols))\n",
        "            # print \"new_vals\", new_vals\n",
        "            # print \"Q = \", Q\n",
        "            # print \"Q_new = \", Q_new\n",
        "            # print \"action = \", action\n",
        "            # print \"target = \", target\n",
        "            # print \"e =\", e\n",
        "            # print \"theta = \\n\", np.reshape(theta.ravel(order='F'), (num_actions, num_rows, num_cols))\n",
        "            # print \"---------------------------------------------------------------------------\"\n",
        "\n",
        "          state = new_state.copy()\n",
        "          activations = new_activations.copy()\n",
        "          action = new_action\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    ep_length[ep] = t\n",
        "    # print \"t = \", t\n",
        "    epsilon *= epsilon_coefficient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "SSF0jT9s6aEF",
        "outputId": "ef7da3b3-6212-43de-8bf7-990515646484"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-00c3ef59fb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# new_state = normalize_state(new_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnew_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mnew_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_activations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnew_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_greedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-76cf0446be7d>\u001b[0m in \u001b[0;36mphi\u001b[0;34m(_state)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0m_phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0m_phi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrbf_den\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_phi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value_left = np.zeros(num_ind)\n",
        "value_nothing = np.zeros(num_ind)\n",
        "value_right = np.zeros(num_ind)\n",
        "\n",
        "# Display each action-value as a heatmap\n",
        "for h in range(num_ind):\n",
        "    current_activations = phi(c[h, :])\n",
        "    value_left[h] += action_value(current_activations, 0, theta)\n",
        "    value_nothing[h] += action_value(current_activations, 1, theta)\n",
        "    value_right[h] += action_value(current_activations, 2, theta)\n",
        "\n",
        "plt.close('all')\n",
        "fig, axes = plt.subplots(ncols=3, sharey=True)\n",
        "plt.setp(axes.flat, aspect=1.0, adjustable='box')\n",
        "im = axes[0].imshow(value_left.reshape((8, 8)), cmap='hot')\n",
        "axes[0].set_title('Action = left')\n",
        "axes[0].set_ylabel('Position')\n",
        "axes[0].set_xlabel('Velocity')\n",
        "im = axes[1].imshow(value_nothing.reshape((8, 8)), cmap='hot')\n",
        "axes[1].set_title('Action = nothing')\n",
        "im = axes[2].imshow(value_right.reshape((8, 8)), cmap='hot')\n",
        "axes[2].set_title('Action = right')\n",
        "# fig.subplots_adjust(bottom=0.2)\n",
        "# cbar_ax = fig.add_axes([0.15, 0.15, 0.7, 0.05])\n",
        "# cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
        "# plt.axis([0, 1, 0, 1])\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(ep_length)\n",
        "plt.title('Episode Length')\n",
        "plt.ylabel('Completion Time')\n",
        "plt.xlabel('Episode')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OBgY23HN7-rG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
